{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4524d2dc",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">Implement Multi-Perception</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512b813",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2427b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd9887",
   "metadata": {},
   "source": [
    "## Write Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5004ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFullyConnected(unittest.TestCase):\n",
    "    \n",
    "    def test_fc_init(self):\n",
    "        fc = FC(n_in = 3, n_out = 5, activation = \"sigmoid\")\n",
    "        self.assertEqual(fc.n_in, 3)\n",
    "        self.assertEqual(fc.n_out, 5)\n",
    "        self.assertEqual(fc.activation, \"sigmoid\")\n",
    "        self.assertEqual(fc.W.shape, (3, 5))\n",
    "        self.assertEqual(fc.dW.shape, (3, 5))\n",
    "    \n",
    "    def test_fc_forward(self):\n",
    "        fc = FC(n_in = 3, n_out = 5, activation = \"sigmoid\")\n",
    "        x = np.zeros((10, 3), dtype=np.float32)\n",
    "        y = fc.forward(x)\n",
    "        error = np.sum(np.abs((y - np.ones_like(y) * 0.5)))\n",
    "        self.assertEqual(y.shape, (10, 5))\n",
    "        self.assertLess(error, 1e-6)\n",
    "\n",
    "    def test_fc_forward_identity(self):\n",
    "        fc = FC(n_in = 3, n_out = 5, activation = None)\n",
    "        x = np.zeros((10, 3), dtype=np.float32)\n",
    "        y = fc.forward(x)\n",
    "        error = np.sum(np.abs(y - np.zeros_like(y)))\n",
    "        self.assertEqual(y.shape, (10, 5))\n",
    "        self.assertLess(error, 1e-6)\n",
    "        \n",
    "    def test_fc_backward(self):\n",
    "        fc = FC(n_in = 3, n_out = 5, activation = \"sigmoid\")\n",
    "        x = np.zeros((10, 3), dtype=np.float32)\n",
    "        y = fc.forward(x)\n",
    "        dx = fc.backward(np.zeros_like(y))\n",
    "        self.assertEqual(dx.shape, x.shape)\n",
    "        self.assertEqual(fc.dW.shape, fc.W.shape)\n",
    "    \n",
    "    def test_fc_backward_identity(self):\n",
    "        fc = FC(n_in = 3, n_out = 5, activation = None)\n",
    "        x = np.zeros((10, 3), dtype=np.float32)\n",
    "        y = fc.forward(x)\n",
    "        dx = fc.backward(np.zeros_like(y))\n",
    "        self.assertEqual(dx.shape, x.shape)\n",
    "        self.assertEqual(fc.dW.shape, fc.W.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409a2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMultiPerceptron(unittest.TestCase):\n",
    "    def test_mlp_init(self):\n",
    "        mlp = MLP(n_ins = 3, hiddens = [5, 2])\n",
    "        layer_0 = mlp.layers[0]\n",
    "        layer_1 = mlp.layers[1]\n",
    "        self.assertEqual(layer_0.W.shape, (3, 5))\n",
    "        self.assertEqual(layer_1.W.shape, (5, 2))\n",
    "        self.assertEqual(layer_1.activation, None)\n",
    "        self.assertEqual(layer_0.activation, \"sigmoid\")\n",
    "        \n",
    "    def test_mlp_init(self):\n",
    "        mlp = MLP(n_ins = 3, hiddens = [5, 2])\n",
    "        layer = FC(n_in = 2, n_out = 1)\n",
    "        mlp.add(layer)\n",
    "        \n",
    "        \n",
    "    def test_mlp_forward(self):\n",
    "        mlp = MLP(n_ins = 3, hiddens = [5, 2])\n",
    "        x = np.zeros((10, 3))\n",
    "        y = mlp.forward(x)\n",
    "        self.assertEqual(y.shape, (10, 2))\n",
    "    \n",
    "    def test_mlp_backward(self):\n",
    "        mlp = MLP(n_ins = 3, hiddens = [5, 2])\n",
    "        x = np.ones((10, 3))\n",
    "        mlp.forward(x)\n",
    "        dy = np.ones((10, 2))\n",
    "        dx = mlp.backward(dy)\n",
    "        self.assertEqual(x.shape, (10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e96e5b",
   "metadata": {},
   "source": [
    "## Implement\n",
    "### Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "04b92e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, n_in, n_out, activation=None):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.W = np.random.randn(self.n_in, self.n_out)\n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.a = None\n",
    "        self.f = None\n",
    "        self.x = None\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def stable_sigmoid(X):\n",
    "        return np.where(X >= 0,\n",
    "                        1 / (1 + np.exp(-X)),\n",
    "                        np.exp(X) / (1 + np.exp(X)))\n",
    "  \n",
    "    def __activation(self, a):\n",
    "        if self.activation in (None, \"linear\"):\n",
    "            f = a.copy()\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            f = self.stable_sigmoid(a)\n",
    "        else:\n",
    "            raise NotImplementError(f\"{self.activation} has been implemented yet\")\n",
    "            \n",
    "        return f\n",
    "    \n",
    "    def __deactivation(self, output_grad, f):\n",
    "        if self.activation in (None, \"linear\"):\n",
    "            da = output_grad.copy()\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            da = f * (1 - f) * output_grad\n",
    "        else:\n",
    "            raise NotImplementError(f\"{self.activation} has been implemented yet\")\n",
    "            \n",
    "        return da\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: N_samples x n_in\n",
    "        # W: n_in x n_out\n",
    "        self.x = x.copy()\n",
    "        self.a = x @ self.W\n",
    "        self.f = self.__activation(self.a)\n",
    "        return self.f\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        # output_grad: n_samples x n_out\n",
    "        da = self.__deactivation(output_grad, self.f)\n",
    "        \"\"\"\"\"\"\n",
    "        # self.x: n_samples x n_in\n",
    "#         self.dW = self.x.T @ self.da # expecting: n_in x n_out\n",
    "        self.dW = np.einsum(\"ij,ik->jk\", self.x, da)\n",
    "        self.dx = da @ self.W.T # n_samples x n_in\n",
    "        \n",
    "        return self.dx\n",
    "    \n",
    "    def get_params(self):\n",
    "        return np.array([self.dW])\n",
    "    \n",
    "    def training(self, learning_rate):\n",
    "        self.W -= learning_rate * self.dW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadd939",
   "metadata": {},
   "source": [
    "## Multi - Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "99eb97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, n_ins, hiddens, layers = None, learning_rate= .01, max_iterations = 1000):\n",
    "        self.n_ins = n_ins\n",
    "        self.hiddens = hiddens\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations \n",
    "            \n",
    "        self.layers = [\n",
    "            FC(n_in = self.n_ins if idx == 0 else self.hiddens[idx - 1],\n",
    "               n_out = self.hiddens[idx],\n",
    "               activation = \"sigmoid\" if idx + 1 != len(self.hiddens) else None) \\\n",
    "            for idx in range(len(self.hiddens))\n",
    "        ]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_copy = x.copy()\n",
    "        for layer in self.layers:\n",
    "            x_copy = layer.forward(x_copy) \n",
    "        return x_copy\n",
    "\n",
    "    def backward(self, output_grad):\n",
    "        ograd_cp = output_grad.copy()\n",
    "        for layer in self.layers[::-1]:\n",
    "            ograd_cp = layer.backward(ograd_cp)\n",
    "            layer.training(self.learning_rate)\n",
    "        \n",
    "        return ograd_cp\n",
    "    \n",
    "    def add(self, layer):\n",
    "        assert(layer.n_in == self.layers[-1].n_out)\n",
    "        if isinstance(layer, FC):\n",
    "            self.layers.append(layer)\n",
    "        else:\n",
    "            raise NotImplementError(\"Not implement yet\")\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Specify SSE \n",
    "        n_samples = X.shape[0]\n",
    "        losses = []\n",
    "        for ite in range(self.max_iterations):\n",
    "            y_hat = self.forward(X)\n",
    "            e = y_hat - y\n",
    "            loss = (e.T @ e)[0, 0]\n",
    "            losses.append(loss)\n",
    "            if ite % 100 == 0:\n",
    "                print(f\"Iteration: {ite}, Loss accuracy {loss}\")\n",
    "\n",
    "            \n",
    "            self.backward(e)\n",
    "        \n",
    "        return loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fa2a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(n_ins = 2, hiddens = [20,  1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e5e5fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e6ae4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "X, _ = make_blobs(n_samples = n_samples, n_features = 1)\n",
    "y = (X ** 2 + 3 * X ).reshape(-1, 1)\n",
    "X = np.c_[X, [1] * n_samples]\n",
    "idx = np.random.permutation(n_samples)\n",
    "\n",
    "X, y = X[idx], y[idx]\n",
    "X_training , y_training = X[:int(0.8 * n_samples)], y[:int(0.8 * n_samples)]\n",
    "X_test, y_test = X[int(0.8 * n_samples):], y[int(0.8 * n_samples):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ee2043dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss accuracy 50184.12731099811\n",
      "Iteration: 100, Loss accuracy 4422.721203560966\n",
      "Iteration: 200, Loss accuracy 4543.956677563802\n",
      "Iteration: 300, Loss accuracy 4239.0064021138105\n",
      "Iteration: 400, Loss accuracy 4447.06895972842\n",
      "Iteration: 500, Loss accuracy 4501.622481556783\n",
      "Iteration: 600, Loss accuracy 4239.041683769878\n",
      "Iteration: 700, Loss accuracy 4434.285404971257\n",
      "Iteration: 800, Loss accuracy 4606.736679490606\n",
      "Iteration: 900, Loss accuracy 4279.713752792479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4465.753933943337"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6c56cf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2389df54ee0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], y, c=\"r\")\n",
    "plt.scatter(X[:, 0], mlp.forward(X) , c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "652071fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_fc_backward (__main__.TestFullyConnected) ... ok\n",
      "test_fc_backward_identity (__main__.TestFullyConnected) ... ok\n",
      "test_fc_forward (__main__.TestFullyConnected) ... ok\n",
      "test_fc_forward_identity (__main__.TestFullyConnected) ... ok\n",
      "test_fc_init (__main__.TestFullyConnected) ... ok\n",
      "test_mlp_backward (__main__.TestMultiPerceptron) ... ok\n",
      "test_mlp_forward (__main__.TestMultiPerceptron) ... ok\n",
      "test_mlp_init (__main__.TestMultiPerceptron) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.029s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x238f66d63a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"], verbosity = 2, exit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78333cfa",
   "metadata": {},
   "source": [
    "## Cơ sở toán học"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c41500",
   "metadata": {},
   "source": [
    "### Tính toán đầu ra của mạng (tính xuôi)\n",
    "\n",
    "Lặp $L$ lần, quy ước $\\mathbf f_0 = \\mathbf x$, với $l = 1,2,\\ldots L$\n",
    "\n",
    "$$ \\begin{align*} \\mathbf a_l &= \\mathbf W_l \\mathbf f_{l-1}\\in\\mathbb R^{p_l}\\\\ \\mathbf f_l &= \\phi_l(\\mathbf a_l)\\in\\mathbb R^{p_l} \\end{align*} $$\n",
    "\n",
    "Tính logit, xác suất (softmax) và hàm lỗi cross-entropy\n",
    "\n",
    "$$ \\begin{align*} \\mathbf f &= \\mathbf f_L \\in\\mathbb R^{C}\\\\ \\bf\\mu &=\\mathcal S(\\mathbf f)\\in\\mathbb R^{C}\\\\ \\ell &= -\\mathbf y^T\\log(\\bf\\mu)\\in\\mathbb R \\end{align*} $$\n",
    "\n",
    "$\\mathbf y$ là **mã hoá one-hot** của nhãn $y\\in\\{1,2,\\ldots, C\\}$ .\n",
    "\n",
    "Mạng nơ-ron có $L-1$ lớp ẩn và một lớp đầu ra.\n",
    "\n",
    "### Lựa chọn hàm kích hoạt\n",
    "\n",
    "- Hàm tuyến tính: $\\phi_l(a) = a$, hay dùng ở lớp cuối cùng\n",
    "- Hàm sigmoid: $\\phi_l(a) = \\sigma(a) = \\frac 1 {1+e^{-a}}$, hay dùng ở các lớp trước lớp cuối cùng (lớp ẩn)\n",
    "- Hàm ReLU: $\\phi_l(a) = \\max(0, a)$\n",
    "- Hàm tanh: $\\phi_l(a) = 2\\sigma(a)-1$\n",
    "\n",
    "💡 Nếu chọn $\\phi_l(a) = a$ với mọi tầng của mạng thì sẽ có lại Hồi quy Logistics (trường hợp con của mạng nơ-ron)\n",
    "\n",
    "\n",
    "\n",
    "### Suy luận bằng mạng nơ-ron\n",
    "\n",
    "**Luật phân lớp**: chọn vị trí phần tử lớn nhất trong $\\mathbf f$ là phân lớp của $\\mathbf x$.\n",
    "\n",
    "### Kích thước của bộ trọng số\n",
    "\n",
    "- Đầu ra của tầng trước là đầu vào của tầng sau: ma trận $\\mathbf W_l\\in \\mathbb R^{p_l\\times p_{l-1}}$, trong đó $p_l$ là số đầu ra của lớp $l$ còn $p_{l-1}$ là số đầu ra của lớp $l-1$.\n",
    "- Quy ước $p_0 = d+1$ là số đầu vào của mạng.\n",
    "- Lớp cuối cùng: $p_L = C$ là số lớp của bài toán phân lớp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29b6c3",
   "metadata": {},
   "source": [
    "### Đạo hàm của hàm lỗi (tính ngược)\n",
    "\n",
    "#### B1. Tính đạo hàm $\\delta_{\\bf \\mu}$\n",
    "\n",
    "$$ \\delta_{\\bf\\mu} = -\\mathbf y^T / \\bf\\mu^T\\in\\mathbb R^{1\\times C} $$\n",
    "\n",
    "<aside> 💡 Lưu ý: vector hàng (dòng)\n",
    "\n",
    "</aside>\n",
    "\n",
    "#### B2. Tính đạo hàm $\\mathbf J_{\\bf\\mu}(\\mathbf f)$\n",
    "\n",
    "$$ \\begin{align*} \\frac{\\partial \\mu_i}{\\partial f_j} &= \\frac{u'v-v'u}{v^2} =\\frac{\\mathbb I(i=j) e^{f_j}\\sum_{c=1}^C e^{f_c}-e^{f_j}e^{f_i}}{(\\sum_{c=1}^C e^{f_c})^2}\\\\ &= \\mathbb I(i=j) \\mu_j - \\mu_i\\mu_j=\\begin{cases}(1-\\mu_i)\\mu_i&i=j\\\\-\\mu_i\\mu_j&i\\neq j\\end{cases}\\\\&=\\begin{bmatrix}(1-\\mu_1)\\mu_1 &-\\mu_2\\mu_1 &\\cdots&-\\mu_K\\mu_1\\\\ -\\mu_1\\mu_2&(1-\\mu_2)\\mu_2 &\\cdots&-\\mu_K\\mu_2\\\\\\vdots&\\vdots&&\\vdots\\\\-\\mu_1\\mu_K &-\\mu_2\\mu_K &\\cdots&(1-\\mu_K)\\mu_K\\end{bmatrix}\\in\\mathbb R^{C\\times C} \\end{align*} $$\n",
    "\n",
    "#### B3. Tính đạo hàm $\\delta_{\\mathbf f}$\n",
    "\n",
    "$$ \\delta_{\\mathbf f_L=}\\delta_{\\mathbf f} = \\delta_{\\bf\\mu}\\mathbf J_{\\bf\\mu}(\\mathbf f)\\in\\mathbb R^{1\\times C} $$\n",
    "\n",
    "Trong trường softmax và cross-entropy thì $\\delta_{\\mathbf f} = \\bf\\mu^T-\\mathbf y^T$.\n",
    "\n",
    "#### B4. Tính đạo hàm $\\mathbf J_{\\mathbf f_l}(\\mathbf a_l)$\n",
    "\n",
    "Hàm tuyến tính $\\phi_l(a) = a$ thì $\\mathbf J_{\\mathbf f_l}(\\mathbf a_l)=\\mathbf I\\in\\mathbb R^{p_l\\times p_l}$\n",
    "\n",
    "Hàm sigmoid $\\phi_l(a) = \\sigma(a)$ thì $\\mathbf J_{\\mathbf f_l}(\\mathbf a_l)=\\mathrm{diag}(f_{l1}(1-f_{l1}),f_{l2}(1-f_{l2}),\\ldots,f_{lp_l}(1-f_{lp_l}))$\n",
    "\n",
    " 💡 Do hàm kích hoạt được tính trên từng phần tử của $\\mathbf a_l$ nên ma trận $\\mathbf J_{\\mathbf f_l}(\\mathbf a_l)$ là ma trận đường chéo\n",
    "\n",
    "#### B5. Tính đạo hàm $\\mathbf J_{\\mathbf a_l}(\\mathbf f_{l-1})$\n",
    "\n",
    "$$ \\mathbf a_l = \\mathbf W_l \\mathbf f_{l-1} $$\n",
    "\n",
    "$$ \\mathbf J_{\\mathbf a_l}(\\mathbf f_{l-1}) = \\mathbf W_l $$\n",
    "\n",
    "#### B6. Tính đạo hàm của $\\mathbf a_l$ đối với $\\mathbf W_l$.\n",
    "\n",
    "$$ \\frac {\\partial a_{li}}{\\partial\\mathbf W_l}=\\begin{bmatrix}0 &0 &\\cdots&0\\\\\\vdots&\\vdots&&\\vdots\\\\ -&\\mathbf f_{l-1}^T&-&-\\\\\\vdots&\\vdots&&\\vdots\\\\0&0&\\cdots&0\\end{bmatrix}\\in\\mathbb R^{p_l\\times p_{l-1}} $$\n",
    "\n",
    "Ma trận gồm toàn các dòng số 0, duy nhất dòng thứ $i$ là đầu vào $\\mathbf f_{l-1}^T$.\n",
    "\n",
    "#### B7. Tính đạo hàm $\\delta_{\\mathbf a_l}, \\delta_{\\mathbf W_l}, \\delta_{\\mathbf f_{l-1}}$\n",
    "\n",
    "$$ \\begin{align*} \\delta_{\\mathbf a_l} &= \\delta_{\\mathbf f_l}\\mathbf J_{\\mathbf f_l}(\\mathbf a_l)\\in\\mathbb R^{1\\times p_l}\\\\ \\delta_{\\mathbf W_l} &= \\delta_{\\mathbf a_l}^T\\mathbf f_{l-1}^T \\in\\mathbb R^{p_l\\times p_{l-1}}\\\\ \\delta_{\\mathbf f_{l-1}}&=\\delta_{\\mathbf a_l}\\mathbf W_l\\in\\mathbb R^{1\\times p_{l-1}} \\end{align*} $$\n",
    "\n",
    "<aside> 💡 Công thức đầu tiên có ma trận đường chéo\n",
    "\n",
    "</aside>\n",
    "\n",
    "💡 Công thức thứ hai có được dựa vào đạo hàm thành phần $\\frac{\\partial \\ell}{\\partial\\mathbf W_l}=\\sum_{i=1}^{p_l}\\frac{\\partial\\ell}{\\partial a_{li}}\\frac {\\partial a_{li}}{\\partial\\mathbf W_l}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
